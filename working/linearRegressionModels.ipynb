{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50921961",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the file as .h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9605cdd-fd2d-49da-9498-60d6ccb202e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install yfinance plotly\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "import joblib, pickle, dill, keras\n",
    "\n",
    "start = '2000-01-01'\n",
    "end = '2024-02-01'\n",
    "stock = 'MSFT'\n",
    "\n",
    "data = yf.download(stock, start, end)\n",
    "\n",
    "# prints the DF\n",
    "# display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb70721-3516-4c09-8ca7-a96883b640cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The 100-day moving average is calculated by summing the past 100 days ClosePx and dividing the result by 100.\n",
    "# returns a series\n",
    "ma_100_days = data.Close.rolling(100).mean()\n",
    "\n",
    "# Plot\n",
    "fig1 = go.Figure()\n",
    "fig1.add_trace(go.Scatter(x=data.index, y=ma_100_days, mode='lines', name='MA100'))\n",
    "fig1.add_trace(go.Scatter(x=data.index, y=data.Close, mode='lines', name='Close Price'))\n",
    "fig1.update_layout(title='Price vs MA100', xaxis_title='Date', yaxis_title='Price')\n",
    "fig1.show()\n",
    "\n",
    "# The 200-day moving average is calculated by summing the past 200 days ClosePx and dividing the result by 200.\n",
    "# returns a series\n",
    "ma_200_days = data.Close.rolling(200).mean()\n",
    "\n",
    "# Plot\n",
    "fig2 = go.Figure()\n",
    "fig2.add_trace(go.Scatter(x=data.index, y=ma_100_days, mode='lines', name='MA100', line=dict(color='red')))\n",
    "fig2.add_trace(go.Scatter(x=data.index, y=ma_200_days, mode='lines', name='MA200', line=dict(color='blue')))\n",
    "fig2.add_trace(go.Scatter(x=data.index, y=data.Close, mode='lines', name='Close Price', line=dict(color='green')))\n",
    "fig2.update_layout(title='Price vs MA100 vs MA200', xaxis_title='Date', yaxis_title='Price')\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b898e916-8bd2-4c02-9f12-482a1cd349a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "1. Drops nans\n",
    "2. sets up initial test/train Dataframes\n",
    "3. Initiates the MinMaxScaler => all ClosePx's will range from 0-1 for normalization\n",
    "'''\n",
    "\n",
    "# Drop NANs\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# takes 80% of the ClosePx for data_train (training)\n",
    "# takes the remaining 20% of the ClosePx for data_test (testing)\n",
    "data_train = pd.DataFrame(data.Close[0: int(len(data)*0.80)])\n",
    "data_test = pd.DataFrame(data.Close[int(len(data)*0.80): len(data)])\n",
    "\n",
    "# Normalization technique\n",
    "# all features will be transformed into the range [0,1] \n",
    "# meaning that the minimum and maximum value of a feature/variable is going to be 0 and 1\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "# print(f\"data_train {data_train.shape}:\\n{data_train.head(2)}\\n\")\n",
    "# print(f\"data_test {data_test.shape}:\\n{data_test.head(2)}\\n\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995ee38a-3958-44be-be76-31b95b31edca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "1. Setup the training sets\n",
    "2. Loop below creates a sliding window with 1 step at a time\n",
    "'''\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "# fit transforms the data\n",
    "data_train_scale = scaler.fit_transform(data_train)\n",
    "\n",
    "# print(data_train_scale.shape) => (4846, 1)\n",
    "\n",
    "# This creates a sliding window 1 step at a time\n",
    "# Loop through the range starting from 100 up to the total number of rows in the dataset `data_train_scale`\n",
    "# Start at 101, grab the first 100 (ClosePx's) and append to x_train then put the 101st into y_train\n",
    "for i in range(100, data_train_scale.shape[0]):\n",
    "    # Creating the input sequence for the model- data_train_scale[i-100:i, 0] represents these 100 data points\n",
    "    x_train.append(data_train_scale[i-100:i, 0])\n",
    "    # Creating the target value for the model\n",
    "    y_train.append(data_train_scale[i, 0])\n",
    "\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "print(f\"x_train.shape {x_train.shape}\\ny_train.shape {y_train.shape}\\n\")\n",
    "print(f\"x_train\\n{x_train[:2]}\\ny_train\\n{y_train[:2]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b23ff4b-4f24-4012-885e-b1c844ae3a78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "1. Setting up x_test and y_test\n",
    "2. First grab the last 100 days from our data_train df as it'll be needed to calc/predict/compare the first price of the y_test ClosePx\n",
    "    - we first gather the last 100 days\n",
    "    - we then run our time window slice code to predict/check prices\n",
    "'''\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "# Need to grab the last 100 days from data_train cuz it will be used to \"predict\" or compare on the first element of the data_test array\n",
    "# Remember that I need 100 previous ClosePx in order to predict the ClosePx of any given day in the future\n",
    "pas_100_days = data_train.tail(100)\n",
    "\n",
    "# Combine both arrays into data_test\n",
    "data_test = pd.concat([pas_100_days, data_test], ignore_index=True)\n",
    "\n",
    "data_test_scale  =  scaler.fit_transform(data_test)\n",
    "\n",
    "# This creates a sliding window 1 step at a time\n",
    "# Loop through the range starting from 100 up to the total number of rows in the dataset `data_train_scale`\n",
    "# Start at 101, grab the first 100 (ClosePx's) and append to x_train then put the 101st into y_train\n",
    "for i in range(100, data_test_scale.shape[0]):\n",
    "    x_test.append(data_test_scale[i-100:i, 0])\n",
    "    y_test.append(data_test_scale[i, 0])\n",
    "\n",
    "# prints out shapes and first three elements    \n",
    "x_test, y_test = np.array(x_test), np.array(y_test)\n",
    "# print(f\"x_test.shape => {x_test.shape}\\ny_test.shape => {y_test.shape}\\n\")\n",
    "# print(f\"x_test\\n{x_test[:2]}\\ny_test\\n{y_test[:2]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d041f338-12fa-49d2-b32e-08863855bc36",
   "metadata": {},
   "source": [
    "## function: make_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0d7726-36e5-4133-995d-1f5734cd79c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_results(model_name:str, model_object, metric:str):\n",
    "    '''\n",
    "    Arguments:\n",
    "    model_name (string): user labeled the model\n",
    "    model_object: a fit GridSearchCV object\n",
    "    metric (string): neg_mean_absolute_error, neg_mean_squared_error or r2\n",
    "\n",
    "    Returns a pandas df with the neg_mean_absolute_error, neg_mean_squared_error and r2 scores\n",
    "    for the model with the best mean 'metric' score across all validation folds.\n",
    "    '''\n",
    "\n",
    "    # Create dictionary that maps input metric to actual metric name in GridSearchCV\n",
    "    metric_dict = {'neg_mean_absolute_error': 'mean_test_neg_mean_absolute_error',\n",
    "                 'neg_mean_squared_error': 'mean_test_neg_mean_squared_error',\n",
    "                 'r2': 'mean_test_r2',\n",
    "                 }\n",
    "\n",
    "    # Get all the results from the CV and put them in a df\n",
    "    cv_results = pd.DataFrame(model_object.cv_results_)\n",
    "\n",
    "    # Isolate the row of the df with the max(metric) score\n",
    "    best_estimator_results = cv_results.iloc[cv_results[metric_dict[metric]].idxmax(), :]\n",
    "\n",
    "    # Extract neg_mean_absolute_error, neg_mean_squared_error, and r2 score from that row\n",
    "    neg_mean_absolute_error = best_estimator_results.mean_test_neg_mean_absolute_error\n",
    "    neg_mean_squared_error = best_estimator_results.mean_test_neg_mean_squared_error\n",
    "    r2 = best_estimator_results.mean_test_r2\n",
    "\n",
    "    # Create table of results\n",
    "    table = pd.DataFrame({'model': [model_name],\n",
    "                        'neg_mean_absolute_error': [neg_mean_absolute_error],\n",
    "                        'neg_mean_squared_error': [neg_mean_squared_error],\n",
    "                        'r2': [r2],\n",
    "                        },\n",
    "                       )\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe261e9c-a19f-4b90-84b7-2f98bbe8c8fa",
   "metadata": {},
   "source": [
    "## function: get_test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b59d56-3fba-4715-9c61-4719bd2cc49c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_test_scores(model_name:str, preds, y_test_data):\n",
    "    '''\n",
    "    Generate a table of test scores.\n",
    "\n",
    "    In:\n",
    "    model_name (string): how the model will be named in the output table\n",
    "    preds: numpy array of test predictions\n",
    "    y_test_data: numpy array of y_test data\n",
    "\n",
    "    Out:\n",
    "    table: a pandas df of neg_mean_absolute_error, neg_mean_squared_error and r2 scores for your model\n",
    "    '''\n",
    "    negative_mean_absolute_error = mean_absolute_error(y_test_data, preds)\n",
    "    negative_mean_squared_error = mean_squared_error(y_test_data, preds)\n",
    "    r2 = r2_score(y_test_data, preds)\n",
    "\n",
    "    table = pd.DataFrame({'model': [model_name],\n",
    "                        'neg_mean_absolute_error': [negative_mean_absolute_error],\n",
    "                        'neg_mean_squared_error': [negative_mean_squared_error],\n",
    "                        'r2': [r2]\n",
    "                        })\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a560fd00-dc25-48cb-a5c5-bec19bd5430b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# LinearRegression and GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59dc73a-67e3-4a4c-9dbc-05961c6abf38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate linear regression model\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Create a dictionary of hyperparameters to tune\n",
    "cv_params = {'fit_intercept': [True, False],\n",
    "             'positive': [True, False],\n",
    "             'copy_X':[True, False]\n",
    "}\n",
    "\n",
    "# Define a set of scoring metrics to capture\n",
    "scoring = ['neg_mean_absolute_error', 'neg_mean_squared_error', 'r2']\n",
    "\n",
    "lr1 = GridSearchCV(lr, cv_params, scoring=scoring, cv=4, refit='neg_mean_absolute_error', n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50da2d5d-39a8-4fcf-ab59-d9c23dc37d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the dims\n",
    "print(f\"x_train dims BEFORE fit => {x_train.shape}\\n\")\n",
    "print(f\"y_train dims BEFORE fit => {y_train.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac92f3fd-c0bc-443b-af3a-6bf5c6e931a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "lr1.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69769367-68e0-402b-a84c-c129bb2d8ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the dims\n",
    "# print(f\"x_train AFTER dims => {x_train.shape}\\n\")\n",
    "# print(f\"y_train AFTER dims => {y_train.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e309df1-45fc-4231-ad77-6ba4cb72d25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to a file\n",
    "\n",
    "with open('./pickledModels/grid_search_lr_model.pkl', 'wb') as file:\n",
    "    pickle.dump(lr1, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f4a069-424c-4bd0-a558-db581e547d4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Obtain best parameters\n",
    "\n",
    "lr1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bfc414-d513-418a-b698-0ec98bf15e17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Call 'make_results()' on the GridSearch object\n",
    "\n",
    "results = make_results('LR CV', lr1, 'neg_mean_absolute_error')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3800b3b0-215b-4bd2-8d55-d2de53b0f66d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get scores on test data\n",
    "\n",
    "lr_preds = lr1.best_estimator_.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af897d3-5867-4d12-929b-0d09177f8b04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get scores on test data\n",
    "\n",
    "lr_test_scores = get_test_scores('LR test', lr_preds, y_test)\n",
    "results = pd.concat([results, lr_test_scores], axis=0)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de8e2c2-346f-4777-bbc7-74751fb5ae2d",
   "metadata": {},
   "source": [
    "# Tensorflow LinearRegression and GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fc71f8-46b3-41ae-9938-f45488e88eff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Important packages for Tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from scikeras.wrappers import KerasRegressor # Needed for GridSearchCV\n",
    "from tensorflow.keras.callbacks import EarlyStopping # for use early stopping to avoid overfitting\n",
    "\n",
    "# Function to create the model using tensor flow\n",
    "# def create_model(optimizer='adam', learning_rate=1e-2):\n",
    "#     model = Sequential()\n",
    "#     model.add(Input(shape=(x_train.shape[1],)))\n",
    "#     model.add(Dense(100, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "#     # model.add(Dense(100, activation='relu'))\n",
    "#     model.add(Dense(1, activation='linear'))\n",
    "#     model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mae'])\n",
    "#     return model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(x_train.shape[1],)))\n",
    "model.add(Dense(100, activation='relu', kernel_regularizer=l2(0.0001)))\n",
    "# model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "opt = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae'])\n",
    "\n",
    "# Wrap the model using the KerasRegressor\n",
    "# Needed to allow compatibility between the Tensorflow object and scikit-learn's GridSearchCV\n",
    "# tf_model = KerasRegressor(model=create_model, verbose=1)\n",
    "tf_model = KerasRegressor(model=model, verbose=1)\n",
    "\n",
    "# Early Stopping variable\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9273e68-53bd-4175-8fbf-907f6acbf271",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a dictionary of hyperparameters to tune\n",
    "cv_params = {'batch_size': [32, 64, 128, 256, 512],\n",
    "             'epochs': [50, 100, 200, 300, 400],\n",
    "             'callbacks': [early_stopping]\n",
    "            }\n",
    "\n",
    "# Define a set of scoring metrics to capture\n",
    "scoring = ['neg_mean_absolute_error', 'neg_mean_squared_error', 'r2']\n",
    "\n",
    "# Instantiate the GridSearchCV object\n",
    "tf_model1 = GridSearchCV(tf_model, cv_params, scoring=scoring, cv=4, refit='neg_mean_absolute_error', n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff13d77-3492-48d9-938d-d7c18bd678c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "tf_model1.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921430e8-9a52-4bae-ad1f-8da6695113e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(tf_model1, 'lrTensorFlow.pkl')\n",
    "# dill.dump('lrTensorFlow.pkl')\n",
    "with open('./pickledModels/lrTensorFlow.dill', 'wb') as file:\n",
    "    dill.dump(tf_model1, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c46d957-8f9f-44ba-b71c-00319cb8514b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Examine best score\n",
    "\n",
    "tf_model1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea7e694-c210-49bf-a961-2e86235601ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Examine best parameters\n",
    "\n",
    "tf_model1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c5fe65-a990-425f-a983-5cf30ac1def9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Call 'make_results()' on the GridSearch object\n",
    "\n",
    "tf_cv_results = make_results('TF CV', tf_model1, 'neg_mean_absolute_error')\n",
    "results = pd.concat([results, tf_cv_results], axis=0)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bc8605-6081-4585-bdf5-f4a5a9dd8fa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get scores on test data\n",
    "\n",
    "tf_preds = tf_model1.best_estimator_.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7b3c77-fb45-4267-b2e9-155192493179",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get scores on test data\n",
    "\n",
    "tf_test_scores = get_test_scores('TF test', tf_preds, y_test)\n",
    "results = pd.concat([results, tf_test_scores], axis=0)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74f1f11-18ef-446d-96cb-d84577f6ce14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534741ed-85f5-4f27-a2f2-b02c8e2d2968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebcde26-cda3-4984-a109-0d62b1290dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
